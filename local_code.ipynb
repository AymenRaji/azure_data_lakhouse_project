{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXtracting and Ingesting Data(Bronz_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_payments = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/payments.csv\")\n",
    "\n",
    "display(df_payments.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_payments.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_riders = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/riders.csv\")\n",
    "\n",
    "display(df_riders.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_riders.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/riders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_stations = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/stations.csv\")\n",
    "\n",
    "display(df_stations.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_stations.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_trips = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/trips.csv\")\n",
    "\n",
    "display(df_trips.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_trips.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE or SaveAsTables(silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_payments\")\n",
    "df = spark.read.format(\"delta\").load(\"/delta/payments\")\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .saveAsTable(\"stag_payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_riders\")\n",
    "spark.sql(\"CREATE TABLE stag_riders USING DELTA LOCATION '/delta/riders'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_trips\")\n",
    "spark.sql(\"CREATE TABLE stag_trips USING DELTA LOCATION '/delta/trips'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_stations\")\n",
    "spark.sql(\"CREATE TABLE stag_stations USING DELTA LOCATION '/delta/stations'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"drop table if exists default.dim_payments\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table default.dim_payments as \n",
    "    select \n",
    "        distinct(payment_id), \n",
    "        date, \n",
    "        amount, \n",
    "        rider_id, \n",
    "        day(date) AS day, \n",
    "        month(date) AS month, \n",
    "        quarter(date) AS quarter, \n",
    "        year(date) AS year, \n",
    "        dayofweek(date) AS day_of_week \n",
    "    from default.stag_payments\n",
    "        \"\"\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"drop table if exists default.dim_riders\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table default.dim_riders as \n",
    "    select \n",
    "        distinct(rider_id), \n",
    "        first_name, \n",
    "        last_name, \n",
    "        address, \n",
    "        birthday, \n",
    "        account_start_date, \n",
    "        account_end_date, \n",
    "        is_member\n",
    "    from default.stag_riders\n",
    "        \"\"\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"drop table if exists default.dim_stations\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table default.dim_stations as \n",
    "    select \n",
    "        distinct(station_id), \n",
    "        name, \n",
    "        latitude, \n",
    "        longitude \n",
    "    from default.stag_stations\n",
    "        \"\"\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"drop table if exists default.dim_trips\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table default.dim_trips as \n",
    "    select \n",
    "        distinct(trip_id), \n",
    "        rideable_type, \n",
    "        start_at, \n",
    "        ended_at,\n",
    "        (ended_at - start_at ) as durtion,\n",
    "        start_station_id,\n",
    "        end_station_id,\n",
    "        rider_id\n",
    "    from default.stag_trips\n",
    "        \"\"\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check if the column exists in the table\n",
    "# if 'trip_id' in spark.table('default.dim_payments').columns:\n",
    "spark.sql(\"drop table if exists default.fact_transactions\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    create table default.fact_transactions as \n",
    "    select \n",
    "        py.payment_id,\n",
    "        ri.rider_id,\n",
    "        trip.trip_id,\n",
    "        stat.station_id,\n",
    "        DATEDIFF(Hour, trip.start_at, trip.ended_at) as duration,\n",
    "        DATEDIFF(YEAR, ri.birthday, trip.start_at) as age\n",
    "    from default.dim_payments as py\n",
    "    left join default.dim_riders as ri on py.rider_id = ri.rider_id\n",
    "    left join default.dim_trips as trip on ri.rider_id = trip.rider_id\n",
    "    left join default.dim_stations as stat on trip.start_station_id = stat.station_id\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
