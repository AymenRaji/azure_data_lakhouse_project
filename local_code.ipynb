{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXtracting and Ingesting Data(Bronz_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_payments = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/payments.csv\") \\\n",
    "    .toDF(\"payment_id\", \"date\",\"amount\",\"rider_id\")\n",
    "\n",
    "display(df_payments.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_payments.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_riders = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/riders.csv\") \\\n",
    "    .toDF(\"rider_id\", \"first_name\", \"last_name\", \"address\", \"birthday\", \"account_start_date\", \"account_end_date\", \"is_member\")\n",
    "\n",
    "display(df_riders.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_riders.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/riders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_stations = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/stations.csv\") \\\n",
    "    .toDF(\"station_id\", \"name\", \"latitude\", \"longitude\") \n",
    "\n",
    "display(df_stations.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_stations.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_trips = spark.read.format(\"csv\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .load(\"dbfs:/FileStore/trips.csv\") \\\n",
    "    .toDF(\"trip_id\", \"rideable_type\", \"start_at\", \"ended_at\", \"start_station_id\", \"end_station_id\", \"rider_id\")\n",
    "\n",
    "display(df_trips.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df_trips.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TABLE or SaveAsTables(silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_payments\")\n",
    "df = spark.read.format(\"delta\").load(\"/delta/payments\")\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .saveAsTable(\"stag_payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_riders\")\n",
    "df = spark.read.format(\"delta\").load(\"/delta/riders\")\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .saveAsTable(\"stag_riders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_trips\")\n",
    "df = spark.read.format(\"delta\").load(\"/delta/trips\")\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .saveAsTable(\"stag_trips\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS stag_stations\")\n",
    "df = spark.read.format(\"delta\").load(\"/delta/stations\")\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .saveAsTable(\"stag_stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS curated_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if spark.catalog.tableExists(\"curated_data.fact_payments\"):\n",
    "    spark.sql(\"drop table curated_data.fact_payments\")\n",
    "\n",
    "df = spark.table(\"stag_payments\")\n",
    "\n",
    "df_transformed = df.withColumn(\n",
    "    \"date_id\",\n",
    "    F.concat(\n",
    "        F.year(F.col(\"date\")),\n",
    "        F.lpad(F.month(F.col(\"date\")), 2, '0'),\n",
    "        F.lpad(F.dayofmonth(F.col(\"date\")), 2, '0')\n",
    "    )\n",
    ").dropDuplicates()\n",
    "\n",
    "display(df_transformed.limit(10))\n",
    "\n",
    "df_transformed.write.mode(\"overwrite\").saveAsTable(\"Curated_data.fact_payments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if spark.catalog.tableExists(\"curated_data.dim_dates\"):\n",
    "    spark.sql(\"drop table curated_data.dim_dates\")\n",
    "\n",
    "df = spark.table(\"default.stag_payments\")\n",
    "df_transformed = df.select(\n",
    "    F.col(\"date\"),\n",
    "    F.concat(\n",
    "        F.year(\"date\"),\n",
    "        F.lpad(F.month(\"date\"), 2, '0'),\n",
    "        F.lpad(F.dayofmonth(\"date\"), 2, '0')\n",
    "    ).alias(\"date_id\"),\n",
    "    F.year(\"date\").alias(\"year\"),\n",
    "    F.month(\"date\").alias(\"month\"),\n",
    "    F.dayofmonth(\"date\").alias(\"day\"),\n",
    "    F.dayofweek(\"date\").alias(\"day_of_week\")\n",
    ").dropDuplicates()\n",
    "\n",
    "df_transformed.write.mode(\"overwrite\").saveAsTable(\"Curated_data.dim_dates\")\n",
    "display(df_transformed.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(\"curated_data.dim_riders\"):\n",
    "    spark.sql(\"drop table default.dim_riders\")\n",
    "\n",
    "\n",
    "df = spark.table(\"default.stag_riders\")\n",
    "\n",
    "df_transformed = df.dropDuplicates()\n",
    "df_transformed.write.mode(\"overwrite\").saveAsTable(\"Curated_data.dim_riders\")\n",
    "\n",
    "display(df_transformed.limit(10))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(\"curated_data.dim_stations\"):\n",
    "    spark.sql(\"drop table curated_data.dim_stations\")\n",
    "\n",
    "df = spark.table(\"default.stag_stations\")\n",
    "\n",
    "df_transformed = df.dropDuplicates()\n",
    "df_transformed.write.mode(\"overwrite\").saveAsTable(\"curated_data.dim_stations\")\n",
    "\n",
    "display(df_transformed.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists(\"curated_data.fact_trips\"):\n",
    "    spark.sql(\"drop table curated_data.fact_trips\")\n",
    "\n",
    "\n",
    "df = spark.table(\"default.stag_trips\").dropDuplicates()\n",
    "df_riders = spark.table(\"default.stag_riders\").dropDuplicates()\n",
    "\n",
    "df_transformed = df.withColumn(\n",
    "    \"date_id\",\n",
    "    F.concat(\n",
    "        F.year(F.col(\"start_at\")),\n",
    "        F.lpad(F.month(F.col(\"start_at\")), 2, '0'),\n",
    "        F.lpad(F.dayofmonth(F.col(\"start_at\")), 2, '0')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_joined = df_transformed.alias(\"df_transformed\").join(\n",
    "    df_riders.alias(\"df_riders\"), \n",
    "    F.col(\"df_transformed.rider_id\") == F.col(\"df_riders.rider_id\"), \n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"duration_hours\",\n",
    "    (F.unix_timestamp(\"df_transformed.ended_at\") - F.unix_timestamp(\"df_transformed.start_at\")) / 3600\n",
    ")\n",
    "\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"rider_age\",\n",
    "    F.year(F.col(\"df_transformed.start_at\")) - F.year(F.col(\"df_riders.birthday\"))\n",
    ")\n",
    "\n",
    "\n",
    "df_result = df_joined.select(\n",
    "    F.col(\"df_transformed.trip_id\"),\n",
    "    F.col(\"df_transformed.rideable_type\"),\n",
    "    F.col(\"df_transformed.start_at\"),\n",
    "    F.col(\"df_transformed.ended_at\"),\n",
    "    F.col(\"df_transformed.start_station_id\"),\n",
    "    F.col(\"df_transformed.end_station_id\"),\n",
    "    F.col(\"df_transformed.date_id\"),\n",
    "    F.col(\"df_transformed.rider_id\"),\n",
    "    F.col(\"duration_hours\").alias(\"duration\"),\n",
    "    F.col(\"rider_age\")\n",
    ")\n",
    "\n",
    "display(df_result.limit(10))\n",
    "\n",
    "df_result.write.mode(\"overwrite\").saveAsTable(\"curated_data.fact_trips\")\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
